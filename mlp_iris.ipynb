{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "mlp_iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/howcanigetyourmind/deeplearning-koreauniversty/blob/master/mlp_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q8ZqUq1sOd8",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow Tutorial - 4. MLP ( Multi Layer Perceptron )\n",
        "\n",
        "본 문서는 TensorFlow 를 사용하여 Deep Learning을 구현하기 위한 기초적인 실습 자료이다.\n",
        "\n",
        "The code and comments are written by Dong-Hyun Kwak <imcomking@gmail.com><br>\n",
        "Upgraed to Tensorflow v1.9 by NamJungGu <nowage@gmail.com> \n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMDRptPnsOeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.reset_default_graph()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NiBxENJtQvy",
        "colab_type": "code",
        "outputId": "cdf15397-0a53-4813-a354-d9ecd92dc011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "source": [
        "!cat iris_labels_test.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.,1.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,1.,0.\r\n",
            "0.,1.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,1.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,1.,0.\r\n",
            "0.,1.,0.\r\n",
            "0.,0.,1.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,1.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,1.,0.\r\n",
            "0.,1.,0.\r\n",
            "0.,0.,1.\r\n",
            "1.,0.,0.\r\n",
            "0.,0.,1.\r\n",
            "1.,0.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,0.,1.\r\n",
            "0.,0.,1.\r\n",
            "0.,0.,1.\r\n",
            "0.,0.,1.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,1.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,1.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,1.,0.\r\n",
            "0.,1.,0.\r\n",
            "1.,0.,0.\r\n",
            "1.,0.,0.\r\n",
            "0.,1.,0.\r\n",
            "0.,0.,1.\r\n",
            "0.,0.,1.\r\n",
            "0.,1.,0.\r\n",
            "0.,0.,1."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5I-MFFbsOeN",
        "colab_type": "code",
        "outputId": "52b248e3-c938-4ada-bf80-5cfdb34888d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#[sepal length, sepal width, petal length, petal width]\n",
        "train_X=np.genfromtxt('iris_data_train.csv', delimiter=',')\n",
        "# [setosa, versicolor, virginica]\n",
        "train_y=np.genfromtxt('iris_labels_train.csv', delimiter=',')\n",
        "\n",
        "test_X=np.genfromtxt('iris_data_test.csv', delimiter=',')\n",
        "test_y=np.genfromtxt('iris_labels_test.csv', delimiter=',')\n",
        "\n",
        "#데이터 shape 을 확인해 봅니다.\n",
        "print(train_X.shape,train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQdn3y6TsOeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hidden Layer 2개(5,6)를 Hidden Layer 3개(2,3,4)로 바꾸기. \n",
        "\n",
        "# placeholder is used for feeding data.\n",
        "x = tf.placeholder(\"float\", shape=[None, 4], name = 'x') # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
        "y_target = tf.placeholder(\"float\", shape=[None, 3], name = 'y_target') # shape argument is optional, but this is useful to debug.\n",
        "\n",
        "\n",
        "# all the variables are allocated in GPU memory\n",
        "W1 = tf.Variable(tf.zeros([4, 2]), name = 'W1')   # create (4 * 5) matrix\n",
        "b1 = tf.Variable(tf.zeros([2]), name = 'b1')        # create (1 * 5) vector\n",
        "h1 = tf.sigmoid(tf.matmul(x, W1) + b1, name = 'h1')   # compute --> sigmoid(weighted summation)\n",
        "\n",
        "\n",
        "# all the variables are allocated in GPU memory\n",
        "W2 = tf.Variable(tf.zeros([2, 3]), name = 'W2')   # create (5 * 6) matrix\n",
        "b2 = tf.Variable(tf.zeros([3]), name = 'b2')        # create (1 * 6) vector\n",
        "h2 = tf.sigmoid(tf.matmul(h1, W2) + b2, name = 'h2')   # compute --> sigmoid(weighted summation)\n",
        "\n",
        "# all the variables are allocated in GPU memory\n",
        "W2a = tf.Variable(tf.zeros([3, 4]), name = 'W2a')   # create (5 * 6) matrix\n",
        "b2a = tf.Variable(tf.zeros([4]), name = 'b2a')        # create (1 * 6) vector\n",
        "h2a = tf.sigmoid(tf.matmul(h2, W2a) + b2a, name = 'h2a')   # compute --> sigmoid(weighted summation)\n",
        "\n",
        "# Repeat again\n",
        "W3 = tf.Variable(tf.zeros([4, 3]), name = 'W3')     # create (6 * 3) matrix\n",
        "b3 = tf.Variable(tf.zeros([3]), name = 'b3')          # create (1 * 3) vector\n",
        "y = tf.nn.softmax(tf.matmul(h2a, W3) + b3, name = 'y')  # compute classification --> softmax(weighted summation)\n",
        "\n",
        "# 최종결과는 ( 투입값 * 3) matrix\n",
        "\n",
        "# define the Loss function\n",
        "cross_entropy = -tf.reduce_sum(y_target*tf.log(y), name = 'cross_entropy')\n",
        "\n",
        "\n",
        "# define optimization algorithm\n",
        "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
        "\n",
        "\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_target, 1))\n",
        "# correct_prediction is list of boolean which is the result of comparing(model prediction , data)\n",
        "\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \n",
        "# tf.cast() : changes true -> 1 / false -> 0\n",
        "# tf.reduce_mean() : calculate the mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQXzwWOGsOee",
        "colab_type": "code",
        "outputId": "7780cfe0-d2c4-444c-b33c-ee809c15bda6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Create Session\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) # open a session which is a envrionment of computation graph.\n",
        "sess.run(tf.global_variables_initializer())# initialize the variables\n",
        "\n",
        "# training the MLP\n",
        "for i in range(10001): # minibatch iteraction\n",
        "    #batch = mnist.train.next_batch(100) # minibatch size\n",
        "    sess.run(train_step, feed_dict={x: train_X, y_target: train_y}) # placeholder's none length is replaced by i:i+100 indexes\n",
        "\n",
        "    if i%1000 == 0:\n",
        "        train_accuracy = sess.run(accuracy, feed_dict={x:train_X, y_target: train_y})\n",
        "        print (\"step %d, training accuracy: %.3f\"%(i, train_accuracy))\n",
        "\n",
        "# for given x, y_target data set\n",
        "print  (\"test accuracy: %g\"% sess.run(accuracy, feed_dict={x: test_X, y_target: test_y}))\n",
        "#sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training accuracy: 0.350\n",
            "step 1000, training accuracy: 0.350\n",
            "step 2000, training accuracy: 0.350\n",
            "step 3000, training accuracy: 0.350\n",
            "step 4000, training accuracy: 0.920\n",
            "step 5000, training accuracy: 0.980\n",
            "step 6000, training accuracy: 0.980\n",
            "step 7000, training accuracy: 0.970\n",
            "step 8000, training accuracy: 0.970\n",
            "step 9000, training accuracy: 0.970\n",
            "step 10000, training accuracy: 0.980\n",
            "test accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}